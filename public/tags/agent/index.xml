<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Agent on Awe-AI</title>
    <link>http://localhost:1313/tags/agent/</link>
    <description>Recent content in Agent on Awe-AI</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>© 2026 Awe-AI Team. All rights reserved.</copyright>
    <lastBuildDate>Wed, 11 Feb 2026 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/agent/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Fanzhe Meng</title>
      <link>http://localhost:1313/team/fanzhe-meng/</link>
      <pubDate>Wed, 11 Feb 2026 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/team/fanzhe-meng/</guid>
      <description>M.S. from RUC</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/team/fanzhe-meng/feature.png" />
    </item>
    
    <item>
      <title>Jiale Zhao</title>
      <link>http://localhost:1313/team/jiale-zhao/</link>
      <pubDate>Wed, 11 Feb 2026 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/team/jiale-zhao/</guid>
      <description>Ph.D. from ICT.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/team/jiale-zhao/feature.png" />
    </item>
    
    <item>
      <title>Guoxin Chen</title>
      <link>http://localhost:1313/team/guoxin-chen/</link>
      <pubDate>Wed, 11 Feb 2026 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/team/guoxin-chen/</guid>
      <description>Focusing on natural language processing and large language model research. Ph.D. from GSAI, RUC.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/team/guoxin-chen/feature.png" />
    </item>
    
    <item>
      <title>IterResearch: Rethinking Long-Horizon Agents with Interaction Scaling</title>
      <link>http://localhost:1313/projects/iter-research/</link>
      <pubDate>Sat, 31 Jan 2026 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/iter-research/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;Overview&#xA;    &lt;div id=&#34;overview&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;&#xA;    &#xA;    &lt;span&#xA;        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100 select-none&#34;&gt;&#xA;        &lt;a class=&#34;text-primary-300 dark:text-neutral-700 !no-underline&#34; href=&#34;#overview&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;&#xA;    &lt;/span&gt;&#xA;    &#xA;&lt;/h2&gt;&#xA;&lt;p&gt;Recent advances in deep-research agents have shown promise for autonomous&#xA;knowledge construction through dynamic reasoning over external sources. However, existing approaches rely on a mono-contextual paradigm that accumulates&#xA;all information in a single, expanding context window, leading to context suffocation and noise contamination that limit their effectiveness on long-horizon&#xA;tasks. We introduce IterResearch, a novel iterative deep-research paradigm that&#xA;revisits long-horizon research through the lens of Interaction Scaling. Instead of&#xA;relying on linear context accumulation, we adopt an MDP-inspired architecture&#xA;with strategic workspace reconstruction. By maintaining an evolving report as&#xA;memory and periodically synthesizing insights, our approach preserves consistent reasoning capacity across arbitrary exploration depths. To effectively train&#xA;this paradigm, we employ Efficiency-Aware Policy Optimization (EAPO), a training strategy that adapts geometric reward discounting to incentivize efficient exploration and utilizes adaptive downsampling for stable distributed training. Extensive experiments demonstrate that IterResearch achieves substantial improvements over existing open-source agents with average +14.5pp across six benchmarks and narrows the gap with frontier proprietary systems. Remarkably, our&#xA;paradigm exhibits unprecedented interaction scaling, extending to 2048 interactions with dramatic performance gains (from 3.5% to 42.5%), and serves as an effective prompting strategy, improving frontier models by up to 19.2pp over ReAct&#xA;on long-horizon tasks. These findings position IterResearch as a versatile solution&#xA;for long-horizon reasoning, effective both as a trained agent and as a prompting&#xA;paradigm for frontier models.&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/projects/iter-research/feature.png" />
    </item>
    
    <item>
      <title>Agent Framework: Building Blocks for Autonomous AI</title>
      <link>http://localhost:1313/projects/agent-framework/</link>
      <pubDate>Fri, 28 Nov 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/projects/agent-framework/</guid>
      <description>Our Agent Framework provides the foundational building blocks for creating autonomous AI systems. It offers a modular architecture with pluggable components for reasoning, tool use, memory management, and environment interaction — enabling rapid prototyping of novel agent designs.</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:1313/projects/agent-framework/feature.svg" />
    </item>
    
  </channel>
</rss>
